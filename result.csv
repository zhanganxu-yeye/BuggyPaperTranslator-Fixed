original_title,translated_title,translated_abstract
"Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts","扩散模型上的元遗忘：防止对已遗忘概念的重新学习","随着扩散模型（DMs）的快速发展，越来越多的工作致力于从预训练的扩散模型中去除有害或受版权保护的概念，以防止模型被滥用。然而观察到，即使在发布前对扩散模型进行了适当的去学习处理，恶意微调仍可能破坏这一过程，使模型重新学习被去除的概念。这部分是因为某些保留在模型中的良性概念（例如“皮肤”）与被去除的概念（例如“裸露”）相关联，进而在微调时促进了被去除概念的重新学习。为了解决这一问题，我们提出了对扩散模型的元去学习（meta‑unlearning）方法。直观上，元去学习后的扩散模型在直接使用时应表现得如同已去学习的模型；此外，如果对元去学习后的模型进行针对已去除概念的恶意微调，模型中保留的相关良性概念将被触发自毁，从而阻碍已去除概念的重新学习。我们的元去学习框架兼容大多数现有的去学习方法，仅需额外加入一个易于实现的元目标。我们通过对 Stable Diffusion 模型（SD‑v1‑4 和 SDXL）进行概念元去学习的实证实验验证了该方法，并辅以大量消融研究。"
"Your Text Encoder Can Be An Object-Level Watermarking Controller","文本编码器可用作对象级水印控制器","隐形水印技术可用于 AI 生成图像的版权保护，实现对 AI 生成媒体的检测与识别。本文提出了一种针对文本到图像（T2I）潜在扩散模型（LDM）的新颖图像水印方法。仅通过微调文本标记嵌入 \(\mathcal W_*\)，即可在图像的特定对象或局部区域实现水印，相较于传统的全图水印提供了更大的灵活性。该方法利用文本编码器在不同 LDM 之间的兼容性，实现对各类 LDM 的即插即用集成。此外，在编码阶段早期引入水印，可提升对后续流水线中对抗扰动的鲁棒性。实验表明，本文方法在 48 位水印下实现了 99% 的比特准确率，并将模型参数量降低了 \(10^5\) 倍，从而实现高效的水印嵌入。"
"MUNBa: Machine Unlearning via Nash Bargaining","MUNBa：通过纳什议价实现机器遗忘","机器擦除（Machine Unlearning，MU）旨在有选择地从模型中删除有害行为，同时保留模型的整体效用。作为一个多任务学习问题，MU 需要在遗忘特定概念/数据的目标与保持通用性能的目标之间进行平衡。对这些遗忘与保持目标的朴素整合可能导致梯度冲突和支配现象，阻碍 MU 算法达到最优解。

为解决梯度冲突和支配问题，我们将 MU 重新表述为一个双人合作博弈，其中两位玩家——遗忘玩家和保持玩家——通过各自的梯度提议共同最大化整体收益并平衡彼此贡献。基于此，受 Nash 博弈论的启发，我们推导出闭式解，以引导模型趋向帕累托驻点。

我们的 MU 形式化保证了一个均衡解，即任何对最终状态的偏离都会导致两位玩家的整体目标下降，从而确保每个目标的最优性。

我们在图像分类和图像生成等多样任务上评估了算法的有效性。大量使用 ResNet、视觉语言模型 CLIP 以及文本到图像扩散模型的实验表明，我们的方法优于最先进的 MU 算法，实现了遗忘与保持之间更佳的权衡。实验结果还凸显了遗忘精度的提升、通用化保持的增强以及对对抗攻击的鲁棒性改进。"
"Sculpting Memory: Multi-Concept Forgetting in Diffusion Models via Dynamic Mask and Concept-Aware Optimization","雕刻记忆：通过动态掩码和概念感知优化实现扩散模型的多概念遗忘","文本到图像（T2I）扩散模型在根据文本提示生成高质量图像方面取得了显著成功。然而，这类模型能够存储海量知识，这在需要选择性遗忘的场景中引发了担忧，例如删除受版权保护的内容、降低偏见或消除有害概念。现有的遗忘方法虽能去除某些概念，但在多概念遗忘方面仍面临不稳定、残留知识持续存在以及生成质量下降等问题。为了解决这些挑战，我们提出了 **Dynamic Mask 与 Concept‑Aware Loss**，一种针对扩散模型多概念遗忘的全新遗忘框架。我们的 **Dynamic Mask** 机制能够根据当前优化状态自适应更新梯度掩码，实现对权重的选择性修改，从而避免对无关知识的干扰。此外，**Concept‑Aware Loss** 通过超类对齐强制语义一致性，显式引导遗忘过程；基于知识蒸馏的正则化损失则确保在顺序遗忘过程中已遗忘的概念仍保持被遗忘。我们进行了大量实验以评估该方法。结果表明，在遗忘效果、输出保真度和语义连贯性方面，尤其是在多概念场景下，我们的方法优于现有遗忘技术。我们的工作为生成模型提供了一个原理清晰、灵活且能够实现稳定高保真遗忘的框架。代码已公开于 https://github.com/coulsonlee/Sculpting-Memory-ICCV-2025"
"PlugMark: A Plug-in Zero-Watermarking Framework for Diffusion Models","PlugMark：用于扩散模型的插件式零水印框架","扩散模型在图像合成领域取得了显著进展，使其知识产权（IP）的保护成为关键问题。现有的 IP 保护方法主要通过改变扩散过程的结构，将水印嵌入生成图像。然而，这些方法不可避免地会降低生成图像的质量，并且在面对微调攻击时尤为脆弱，尤其是针对诸如 Stable Diffusion（SD）等开源模型。本文提出了 PlugMark，一种新颖的插件式零水印框架用于扩散模型。PlugMark 的核心思想基于两个观察：分类器可以通过其决策边界唯一表征，扩散模型可以通过从训练数据中获取的知识唯一表示。基于此，我们引入了一个扩散知识提取器，可插入扩散模型以提取其知识并输出分类结果。随后，PlugMark 根据该分类结果生成边界表示，作为零失真水印，唯一表示决策边界，进而代表扩散模型的知识。由于仅需对提取器进行训练，原始扩散模型的性能不受影响。大量实验结果表明，PlugMark 能够稳健地从原始模型及其后处理版本中提取高置信度零水印，并能够有效地区分未经过后处理的扩散模型。"
"ZIUM: Zero-Shot Intent-Aware Adversarial Attack on Unlearned Models","ZIUM：针对未学习模型的零样本意图感知对抗攻击","机器遗忘（Machine Unlearning，MU）通过从深度学习模型中移除特定数据点或概念，以提升隐私保护并防止生成敏感内容。对抗性提示可以利用已遗忘模型生成包含被移除概念的内容，构成显著的安全风险。然而，现有对抗攻击方法在生成符合攻击者意图的内容时仍面临挑战，并且在寻找成功提示的过程中计算成本高昂。为解决这些问题，我们提出 ZIUM——一种面向已遗忘模型的零样本意图感知对抗攻击方法，能够灵活定制目标攻击图像以体现攻击者的意图。此外，ZIUM 支持零样本对抗攻击，无需对已攻击的未学习概念进行额外优化。对多种 MU 场景的评估表明，ZIUM 在基于用户意图提示成功定制内容方面表现出色，攻击成功率优于现有方法。同时，其零样本对抗攻击显著降低了对已攻击未学习概念的攻击时间。"
"SAUCE: Selective Concept Unlearning in Vision-Language Models with Sparse Autoencoders","SAUCE：使用稀疏自编码器对视觉‑语言模型进行选择性概念遗忘","视觉语言模型（VLM） 的遗忘方法主要借鉴大语言模型（LLM）的技术，依赖于需要大量标注遗忘集合的权重更新。此外，这些方法在粗粒度上执行遗忘，常导致过度遗忘并降低模型效用。为解决该问题，我们提出 SAUCE，一种利用稀疏自编码器（SAE）实现细粒度、选择性概念遗忘的创新方法。简而言之，SAUCE 首先训练 SAE 以捕获高维、语义丰富的稀疏特征；随后识别与待遗忘目标概念最相关的特征。在推理阶段，SAUCE 有选择地修改这些特征，以抑制特定概念，同时保留无关信息。我们在两种不同的 VLM 上——LLaVA‑v1.5‑7B 和 LLaMA‑3.2‑11B‑Vision‑Instruct——进行评估，涵盖两类任务：具体概念遗忘（对象和体育场景）与抽象概念遗忘（情感、颜色和材质），共计 60 个概念。大量实验表明，SAUCE 在遗忘质量上比最先进的方法提升 18.04%，且保持了相当的模型效用。此外，我们还考察了 SAUCE 对常用对抗攻击的鲁棒性、跨模型的可迁移性以及在处理多重并发遗忘请求时的可扩展性。研究结果表明，SAUCE 是一种有效且可扩展的 VLM 选择性概念遗忘解决方案。"
"DADet: Safeguarding Image Conditional Diffusion Models against Adversarial and Backdoor Attacks via Diffusion Anomaly Detection","DADet：通过扩散异常检测保护图像条件扩散模型免受对抗攻击和后门攻击","尽管图像条件扩散模型展示了令人印象深刻的生成能力，但在面对后门攻击和对抗攻击时表现出高度脆弱性。本文定义了一种称为扩散异常的情景，即在攻击下的逆过程生成结果与正常结果出现显著偏离。通过分析扩散异常的形成机制，我们揭示了扰动在逆过程中的放大方式以及在结果中的累积效应。基于此分析，我们指出了发散现象和同质化现象，这两者导致扩散过程显著偏离正常过程并且多样性下降。利用这两种现象，我们提出了一种名为扩散异常检测（Diffusion Anomaly Detection, DADet）的方法，以有效检测后门攻击和对抗攻击。大量实验表明，我们的方案在防御后门攻击和对抗攻击方面取得了卓越的性能。具体而言，在后门攻击检测方面，我们的方法在包括 MS COCO 和 CIFAR-10 在内的不同数据集上实现了 99% 的 F1 分数。对于对抗样本的检测，F1 分数在三种对抗攻击和两项不同任务上均超过 84%，分别在 MS COCO 和 Places365 数据集上进行评估。"
"Unlearning the Noisy Correspondence Makes CLIP More Robust","消除噪声对应可提升 CLIP 的鲁棒性","视觉语言模型（VLM）对数据的需求从早期的数百万规模不断扩大到如今的数十亿规模，这与数据质量之间形成了难以承受的权衡，并不可避免地引入了噪声对应（NC）样本。毫无疑问，这类语义不相关的数据会显著削弱 VLM 的性能。以往的工作主要通过估计更精细的对齐来提供更准确的指导。然而，这类从头训练 VLM 的资源密集型流程难以满足实际的数据需求。本文提出一种全新的视角，直接消除预训练 VLM 中噪声对应的有害影响。具体而言，我们提出 NCU——噪声对应遗忘（Noisy Correspondence Unlearning）微调框架，通过遗忘已学习的噪声知识，高效提升 VLM 的鲁棒性。NCU 的关键在于学习最困难的负样本信息，可为假阳性和假阴性提供明确的遗忘方向。该双目标遗忘过程可形式化为统一的最优传输目标，实现快速微调。我们在主流的 CLIP 模型上对多项下游任务进行验证。值得注意的是，NCU 在零样本迁移上超越了鲁棒的预训练方法，同时计算开销更低。代码已公开于 https://github.com/hhc1997/NCU。"
"ROAR: Reducing Inversion Error in Generative Image Watermarking","ROAR：降低生成式图像水印中的反演误差","生成图像水印实现了对生成图像的主动检测与可追溯性。现有方法中，基于反演的框架通过在扩散过程之前将水印注入潜在表示，实现了高度隐蔽的水印嵌入。该方法的鲁棒性依赖于嵌入机制和反演精度。然而，以往工作主要聚焦于优化嵌入过程，忽视了显著影响提取保真度的反演误差。本文针对反演误差挑战，提出了 ROAR——一种基于双域优化的框架，旨在缓解两类关键误差来源：1）潜在域误差，由于固有的近似假设在反演步骤中累积；2）像素域误差，由 JPEG 压缩等通道失真引起。为解决这些问题，我们引入了两个新颖组件：① 再生式优化（Regeneration‑based Optimization，RO）机制，通过可优化的起始潜在向量最小化潜在域误差；② 基于专家混合（Mixture of Experts，MoE）的失真自适应恢复（distortion‑adaptive restoration，AR）网络，有效从像素级失真中恢复水印分布。大量实验表明，ROAR 显著降低了反演误差并提升了水印提取的鲁棒性，从而提高了生成图像水印的可靠性。"
"DIA: The Adversarial Exposure of Deterministic Inversion in Diffusion Models","DIA：对抗性揭示扩散模型中的确定性反演","扩散模型已被证明是强大的表征学习器，在多个领域展示了最先进的性能。除加速采样外，DDIM 还支持将真实图像反演回其潜在码。该反演操作的直接继承应用是真实图像编辑，其中反演产生的潜在轨迹可在编辑图像的合成过程中使用。遗憾的是，这一实用工具使恶意用户能够更轻松地合成误导性或深度伪造内容，从而促进了不道德、滥用以及侵犯隐私和版权的内容传播。虽然防御算法如 AdvDM 和 Photoguard 已被证明能够破坏这些图像的扩散过程，但其目标与测试时迭代去噪轨迹之间的不匹配导致破坏性能较弱。在本工作中，我们提出了 DDIM 反演攻击（DIA），针对集成的 DDIM 轨迹路径进行攻击。实验结果表明，该方法能够有效破坏，并在各种编辑方法上超越先前的防御手段。我们相信，我们的框架和结果能够为工业界和学术界提供针对 AI 恶意使用的实用防御方案。我们的代码已公开于此：https://anonymous.4open.science/r/DIA-13419/."
"TrustMark: Robust Watermarking and Watermark Removal for Arbitrary Resolution Images","TrustMark：任意分辨率图像的鲁棒水印嵌入与去除","不可感知的数字水印在版权保护、误信息防范以及负责任的生成式人工智能中具有重要意义。我们提出了 TrustMark——一种利用时空光谱损失函数和 1×1 卷积层来提升编码质量的水印方法。TrustMark 对就地扰动和非就地扰动均具备鲁棒性，同时保持图像质量高于 43 dB。另有 ReMark——一种面向重新加水印的水印去除方法，并配备了一种简洁而有效的算法，使 TrustMark 与 ReMark 能在任意分辨率下运行。我们的两种方法在三个基准测试上实现了最先进的性能。"
"AVTrustBench: Assessing and Enhancing Reliability and Robustness in Audio-Visual LLMs","AVTrustBench：评估与提升音视频大型语言模型的可靠性与鲁棒性","随着多模态大型语言模型（MLLMs）的快速发展，近期出现了若干诊断基准用于评估这些模型的多模态推理能力。然而，这些基准主要局限于对视觉方面的评估，未能考察整体的音视频（AV）理解能力。此外，目前尚缺乏针对音视频大型语言模型（AVLLMs）在面对扰动输入时校准其响应能力的基准。为此，我们提出了音视频可信度评估基准（Audio-Visual Trustworthiness assessment Benchmark，AVTrustBench），该基准包含 60 万条样本，覆盖 9 项精心设计的任务，分别从对抗攻击（Adversarial Attack）、组合推理（Compositional Reasoning）和模态特定依赖（Modality-specific Dependency）三个维度评估 AVLLMs 的能力。基于该基准，我们对 16 种最先进的 AVLLMs 进行了广泛评测。结果表明，大多数现有模型在实现类人理解方面仍有显著不足，为未来研究方向提供了宝贵的洞见。为克服现有方法的局限性，我们进一步提出了一种鲁棒、模型无关的校准音视频偏好优化训练策略（CAVPref），在全部 9 项任务上实现了最高 30.19% 的性能提升。"
