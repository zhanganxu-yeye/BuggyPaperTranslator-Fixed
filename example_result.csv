title,authors,abstract,date,paper_url,score,title_cn,abstract_cn
Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts,"Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin","With the rapid progress of diffusion models (DMs), significant efforts are being made to unlearn harmful or copyrighted concepts from pretrained DMs to prevent potential model misuse. However, it is observed that even when DMs are properly unlearned before release, malicious finetuning can compromise this process, causing DMs to relearn the unlearned concepts. This occurs partly because certain benign concepts (e.g., ""skin"") retained in DMs are related to the unlearned ones (e.g., ""nudity""), facilitating their relearning via finetuning. To address this, we propose meta-unlearning on DMs. Intuitively, a meta-unlearned DM should behave like an unlearned DM when used as is; moreover, if the meta-unlearned DM undergoes malicious finetuning on unlearned concepts, the related benign concepts retained within it will be triggered to self-destruct, hindering the relearning of unlearned concepts. Our meta-unlearning framework is compatible with most existing unlearning methods, requiring only the addition of an easy-to-implement meta objective. We validate our approach through empirical experiments on meta-unlearning concepts from Stable Diffusion models (SD-v1-4 and SDXL), supported by extensive ablation studies.",2025,https://openaccess.thecvf.com/content/ICCV2025/html/Gao_Meta-Unlearning_on_Diffusion_Models_Preventing_Relearning_Unlearned_Concepts_ICCV_2025_paper.html,0.99609375,扩散模型的元消除学习：防止已消除概念的重新学习,随着扩散模型（DM）快速发展，研究者正致力于从预训练的DM中消除有害或受版权保护的概念，以防止模型被滥用。然而观察到，即使在发布前对DM进行适当的消除学习，恶意微调仍可能破坏该过程，使DM重新学习被消除的概念。这部分是因为DM中保留的某些良性概念（例如“皮肤”）与被消除的概念（例如“裸露”）相关，微调时能够促进其重新学习。为了解决此问题，我们提出了扩散模型的元消除学习。直观地，元消除后的DM在直接使用时应表现为已消除的DM；此外，如果对元消除的DM进行针对已消除概念的恶意微调，模型内部保留的相关良性概念将被触发自毁，从而阻碍已消除概念的重新学习。我们的元消除学习框架兼容大多数现有的消除方法，仅需额外加入一个易于实现的元目标。我们在Stable Diffusion模型（SD‑v1‑4 和 SDXL）上进行概念元消除的实证实验，并通过大量消融研究予以验证。
...